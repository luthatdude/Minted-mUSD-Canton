# Canton Participant Node — Production Deployment
#
# IMPORTANT: Canton participants are stateful. This runs as a single replica
# backed by PostgreSQL. For HA, use Canton's built-in domain sequencer with
# multiple participants connected to the same domain, NOT replica scaling.
apiVersion: v1
kind: Service
metadata:
  name: canton-participant
  namespace: musd-canton
  labels:
    app.kubernetes.io/name: canton-participant
    app.kubernetes.io/component: ledger
spec:
  type: ClusterIP
  ports:
    - name: ledger-api
      port: 5011
      targetPort: 5011
      protocol: TCP
    # Removed admin-api port from Service exposure
    # Admin API is bound to localhost only (see participant-config.yaml)
    # Use kubectl port-forward for admin access when needed
    - name: json-api
      port: 7575
      targetPort: 7575
      protocol: TCP
  selector:
    app.kubernetes.io/name: canton-participant
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: canton-participant
  namespace: musd-canton
  labels:
    app.kubernetes.io/name: canton-participant
    app.kubernetes.io/component: ledger
    owner: minted-protocol
  annotations:
    email: "team@mintedprotocol.com"
spec:
  replicas: 1  # Stateful — do NOT scale without domain sequencer
  strategy:
    type: RollingUpdate    # maxSurge:0 prevents dual-write to same DB
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: canton-participant
  template:
    metadata:
      labels:
        app.kubernetes.io/name: canton-participant
        app.kubernetes.io/component: ledger
      annotations:
        # Force rollout on config change
        # Inject real configmap hash at deploy time:
        #   kubectl annotate ... checksum/config=$(sha256sum k8s/canton/participant-config.yaml | cut -d' ' -f1)
        checksum/config: "__INJECT_AT_DEPLOY_TIME__"
    spec:
      serviceAccountName: canton-participant
      dnsConfig:
        options:
          - name: ndots
            value: "2"
      affinity:
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 1
              preference:
                matchExpressions:
                  - key: kubernetes.io/os
                    operator: In
                    values:
                      - linux
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
        seccompProfile:
          type: RuntimeDefault
      # Wait for postgres to be ready before starting Canton
      initContainers:
        - name: wait-for-postgres
          # Pin image to SHA256 digest for supply chain security
          image: busybox@sha256:9ae97d36d26566ff84e8893c64a6dc4fe8ca6d1144bf5b87b2b85a32def253c7
          command: ['sh', '-c', 'until nc -z postgres.musd-canton.svc.cluster.local 5432; do echo "Waiting for PostgreSQL..."; sleep 2; done']
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop: ["ALL"]
            readOnlyRootFilesystem: true
          resources:
            requests:
              cpu: 10m
              memory: 16Mi
            limits:
              cpu: 50m
              memory: 32Mi
        # INFRA-CRIT-01: Generate JWT token for JSON API authentication
        # Uses the jwt-secret from json-api-credentials to create a signed token
        # FIX(INFRA-C-01): Use alpine instead of busybox — busybox lacks openssl,
        # which is required by the HMAC-SHA256 JWT signing command below.
        - name: generate-json-api-token
          image: alpine:3.19@sha256:c5b1261d6d3e43071626931fc004f70149baeba2c8ec672bd4f27761f8e1ad6b
          command:
            - sh
            - -c
            - |
              # Generate HMAC-SHA256 JWT with least-privilege claims
              # Previously used "actAs":["operator"] which grants admin-level write access.
              # JSON API should only need readAs for most queries; write operations should
              # use separate, scoped tokens generated by the application layer.
              HEADER=$(printf '{"alg":"HS256","typ":"JWT"}' | base64 | tr -d '=' | tr '/+' '_-' | tr -d '\n')
              # Short-lived token (1h instead of 24h), read-only claims
              # For write operations, the relay/bot services should generate their own
              # scoped tokens with the minimum necessary actAs claims.
              EXP=$(($(date +%s) + 3600))
              PAYLOAD=$(printf '{"https://daml.com/ledger-api":{"ledgerId":"canton","applicationId":"json-api","readAs":["operator"]},"exp":%d}' "$EXP" | base64 | tr -d '=' | tr '/+' '_-' | tr -d '\n')
              UNSIGNED="${HEADER}.${PAYLOAD}"
              # Sign with HMAC-SHA256 using jwt-secret
              SIG=$(printf '%s' "$UNSIGNED" | openssl dgst -sha256 -hmac "$(cat /etc/jwt-secret/jwt-secret)" -binary | base64 | tr -d '=' | tr '/+' '_-' | tr -d '\n')
              printf '%s.%s' "$UNSIGNED" "$SIG" > /etc/canton/secrets/json-api-token
              echo "JWT token generated successfully (1h expiry, readAs-only)"
          volumeMounts:
            - name: json-api-secrets
              mountPath: /etc/canton/secrets
            - name: jwt-secret-vol
              mountPath: /etc/jwt-secret
              readOnly: true
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop: ["ALL"]
          resources:
            requests:
              cpu: 10m
              memory: 16Mi
            limits:
              cpu: 50m
              memory: 32Mi
      containers:
        - name: canton
          # Pin Canton image to SHA256 digest for supply chain security
          # Canton Community 3.4.10 — aligned with daml.yaml sdk-version: 3.4.10
          # SDK 3.x ships Canton participant as a separate image (not daml-sdk)
          # The v2 HTTP JSON API is built into the participant (no separate json-api sidecar needed)
          # TODO: Pin to SHA256 digest after pulling from registry:
          #   docker pull digitalasset/canton-community:3.4.10
          #   docker inspect --format='{{index .RepoDigests 0}}' digitalasset/canton-community:3.4.10
          image: digitalasset/canton-community:3.4.10
          args:
            - "-c"
            - "/etc/canton/participant.conf"
            - "--bootstrap"
            - "/etc/canton/init.canton"
          ports:
            - name: ledger-api
              containerPort: 5011
              protocol: TCP
            - name: admin-api
              containerPort: 5012
              protocol: TCP
          env:
            - name: CANTON_DB_HOST
              value: postgres.musd-canton.svc.cluster.local
            - name: CANTON_DB_PORT
              value: "5432"
            - name: CANTON_DB_NAME
              value: canton
            # INFRA-H-04: DB credentials read from volume-mounted secrets at /run/secrets/
            # Canton HOCON config references CANTON_DB_USER and CANTON_DB_PASSWORD env vars,
            # which are populated from files by the entrypoint wrapper (see command override below)
            - name: JAVA_OPTS
              value: "-Xmx2g -Xms1g -XX:+UseG1GC"
          # INFRA-H-04: Wrap entrypoint to load credentials from mounted secret files
          # into env vars before launching Canton (HOCON config reads these env vars)
          command:
            - /bin/sh
            - -c
            - |
              export CANTON_DB_USER="$(cat /run/secrets/db-username)"
              export CANTON_DB_PASSWORD="$(cat /run/secrets/db-password)"
              exec /app/bin/canton -c /etc/canton/participant.conf --bootstrap /etc/canton/init.canton
          resources:
            requests:
              cpu: "1"
              memory: 2Gi
            limits:
              cpu: "4"
              memory: 4Gi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop: ["ALL"]
            readOnlyRootFilesystem: true
          volumeMounts:
            - name: canton-config
              mountPath: /etc/canton
              readOnly: true
            - name: tls-certs
              mountPath: /etc/canton/tls
              readOnly: true
            # INFRA-M-01: Mount PostgreSQL CA certificate for sslmode=verify-full
            - name: postgres-ca-cert
              mountPath: /etc/canton/tls/postgres-ca.crt
              subPath: ca.crt
              readOnly: true
            - name: tmp
              mountPath: /tmp
            # INFRA-H-04: Mount DB credentials as files instead of env vars
            - name: db-credentials
              mountPath: /run/secrets/db-username
              subPath: username
              readOnly: true
            - name: db-credentials
              mountPath: /run/secrets/db-password
              subPath: password
              readOnly: true
          livenessProbe:
            grpc:
              port: 5011
            initialDelaySeconds: 60
            periodSeconds: 15
            timeoutSeconds: 5
            failureThreshold: 4
          readinessProbe:
            grpc:
              port: 5011
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3
          startupProbe:
            grpc:
              port: 5011
            initialDelaySeconds: 10
            periodSeconds: 5
            failureThreshold: 30  # 150s max startup

        # NOTE: The separate json-api sidecar is NO LONGER NEEDED with Canton 3.x.
        # The v2 HTTP JSON API is built into the Canton participant and served on port 7575.
        # The old daml-sdk json-api served the deprecated v1 endpoints (/v1/query, /v1/exercise, /v1/create).
        # Canton 3.x participant natively serves v2 endpoints:
        #   POST /v2/state/active-contracts    (replaces /v1/query)
        #   POST /v2/commands/submit-and-wait  (replaces /v1/create & /v1/exercise)
        #   GET  /v2/state/ledger-end
        #   GET  /v2/users, /v2/packages
        # JWT authentication is configured in participant.conf (canton.participants.*.http-ledger-api-experimental)
        - name: json-api-health
          # Lightweight sidecar that only exposes /livez and /readyz for K8s probes
          # pointing at the participant's built-in HTTP JSON API on port 7575
          image: busybox@sha256:9ae97d36d26566ff84e8893c64a6dc4fe8ca6d1144bf5b87b2b85a32def253c7
          command:
            - "sh"
            - "-c"
            - "echo 'json-api-health sidecar: participant serves v2 API on :7575 natively'; sleep infinity"
          env:
            - name: CANTON_HTTP_PORT
              value: "7575"
          ports:
            - name: json-api
              containerPort: 7575
              protocol: TCP
          resources:
            requests:
              cpu: 250m
              memory: 512Mi
            limits:
              cpu: "1"
              memory: 1Gi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop: ["ALL"]
            readOnlyRootFilesystem: true
          volumeMounts:
            - name: tmp
              mountPath: /tmp
            # Mount JWT secrets for JSON API authentication
            - name: json-api-secrets
              mountPath: /etc/canton/secrets
              readOnly: true
            # INFRA-H-04: Mount JWT secret as file instead of env var
            - name: jwt-credentials
              mountPath: /run/secrets/jwt-secret
              subPath: jwt-secret
              readOnly: true
          livenessProbe:
            httpGet:
              path: /livez
              port: 7575
            initialDelaySeconds: 30
            periodSeconds: 15
            timeoutSeconds: 5
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /readyz
              port: 7575
            initialDelaySeconds: 15
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3

      volumes:
        - name: canton-config
          configMap:
            name: canton-config
        - name: tls-certs
          secret:
            secretName: canton-tls
        # JSON API authentication secrets (writable for init-container token generation)
        - name: json-api-secrets
          emptyDir:
            sizeLimit: 1Mi
        # INFRA-CRIT-01: JWT signing key for token generation
        - name: jwt-secret-vol
          secret:
            secretName: json-api-credentials
        # INFRA-M-01: PostgreSQL CA certificate for verify-full SSL mode
        # Must contain ca.crt key with the PEM-encoded CA that signed the PostgreSQL server cert
        - name: postgres-ca-cert
          secret:
            secretName: postgres-ca-cert
        # INFRA-H-04: DB credentials mounted as files (read from /run/secrets/)
        - name: db-credentials
          secret:
            secretName: postgres-credentials
        # INFRA-H-04: JWT credentials mounted as files (read from /run/secrets/)
        - name: jwt-credentials
          secret:
            secretName: json-api-credentials
        - name: tmp
          emptyDir:
            sizeLimit: 500Mi
      topologySpreadConstraints:
        - maxSkew: 1
          topologyKey: topology.kubernetes.io/zone
          whenUnsatisfiable: DoNotSchedule
          labelSelector:
            matchLabels:
              app.kubernetes.io/name: canton-participant
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: canton-participant
  namespace: musd-canton
  labels:
    app.kubernetes.io/name: canton-participant
automountServiceAccountToken: false
---
# ============================================================
# PARTICIPANT NETWORKPOLICY
# Accept ingress from relay/validators on Ledger API + JSON API
# Egress to PostgreSQL + DNS only
# ============================================================
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: canton-participant-netpol
  namespace: musd-canton
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/name: canton-participant
  policyTypes:
    - Ingress
    - Egress
  ingress:
    # Ledger API from relay and validators
    - from:
        - podSelector:
            matchLabels:
              app.kubernetes.io/name: bridge-relay
        - podSelector:
            matchLabels:
              app.kubernetes.io/name: bridge-validator
      ports:
        - port: 5011
          protocol: TCP
    # JSON API from relay (v2 HTTP)
    - from:
        - podSelector:
            matchLabels:
              app.kubernetes.io/name: bridge-relay
      ports:
        - port: 7575
          protocol: TCP
    # Kubelet probes (gRPC on 5011, HTTP on 7575)
    - ports:
        - port: 5011
          protocol: TCP
        - port: 7575
          protocol: TCP
  egress:
    # PostgreSQL
    - to:
        - podSelector:
            matchLabels:
              app.kubernetes.io/name: postgres
      ports:
        - port: 5432
          protocol: TCP
    # DNS
    - to:
        - namespaceSelector: {}
      ports:
        - port: 53
          protocol: UDP
        - port: 53
          protocol: TCP
