# Minted Bridge - Docker Compose
# Use Docker secrets for sensitive values instead of env vars
# Added network isolation, resource limits, and read-only rootfs
# Health check binds to localhost
#
# Usage:
#   docker-compose up relay         # Start relay service only
#   docker-compose up validator1    # Start validator 1
#   docker-compose up               # Start everything

# Removed deprecated 'version' field (docker compose v2+ ignores it)

# Define secrets (files must be created on host)
secrets:
  canton_token:
    file: ./secrets/canton_token
  bridge_private_key:
    file: ./secrets/bridge_private_key
  validator1_aws_access_key:
    file: ./secrets/validator1_aws_access_key
  validator1_aws_secret_key:
    file: ./secrets/validator1_aws_secret_key
  validator2_aws_access_key:
    file: ./secrets/validator2_aws_access_key
  validator2_aws_secret_key:
    file: ./secrets/validator2_aws_secret_key
  validator3_aws_access_key:
    file: ./secrets/validator3_aws_access_key
  validator3_aws_secret_key:
    file: ./secrets/validator3_aws_secret_key

# Network isolation
networks:
  bridge_internal:
    driver: bridge
    internal: true
  bridge_external:
    driver: bridge

services:
  # ============================================================
  # RELAY SERVICE
  # Bridges finalized attestations from Canton to Ethereum
  # ============================================================
  relay:
    build:
      context: .
      dockerfile: Dockerfile
    command: ["npm", "run", "relay:prod"]
    environment:
      - CANTON_HOST=${CANTON_HOST:-canton}
      - CANTON_PORT=${CANTON_PORT:-6865}
      - CANTON_USE_TLS=${CANTON_USE_TLS:-true}
      - CANTON_PARTY=${CANTON_PARTY}
      - ETHEREUM_RPC_URL=${ETHEREUM_RPC_URL}
      - BRIDGE_CONTRACT_ADDRESS=${BRIDGE_CONTRACT_ADDRESS}
      - CONFIRMATIONS=${CONFIRMATIONS:-2}
      - POLL_INTERVAL_MS=${POLL_INTERVAL_MS:-5000}
      - HEALTH_PORT=8080
      # Bind health server to localhost
      - HEALTH_BIND_HOST=127.0.0.1
      - NODE_ENV=production
    # Mount secrets instead of env vars for sensitive values
    # Renamed from relayer_private_key to match code's readSecret('bridge_private_key')
    secrets:
      - canton_token
      - bridge_private_key
    # Only expose health port to localhost
    ports:
      - "127.0.0.1:8080:8080"
    restart: unless-stopped
    # Resource limits and security hardening
    read_only: true
    tmpfs:
      - /tmp
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '1.0'
        reservations:
          memory: 256M
    security_opt:
      - no-new-privileges:true
    networks:
      - bridge_internal
      - bridge_external
    # Use node instead of curl (not available in alpine)
    healthcheck:
      test: ["CMD", "node", "-e", "const http = require('http'); http.get('http://127.0.0.1:8080/health', (r) => process.exit(r.statusCode === 200 ? 0 : 1)).on('error', () => process.exit(1))"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

  # ============================================================
  # YIELD SYNC SERVICE
  # Unified cross-chain yield distribution
  # Syncs global share price between Ethereum SMUSD and Canton
  # ============================================================
  yield-sync:
    build:
      context: .
      dockerfile: Dockerfile
    command: ["npm", "run", "yield-sync:prod"]
    environment:
      - CANTON_HOST=${CANTON_HOST:-canton}
      - CANTON_PORT=${CANTON_PORT:-6865}
      - CANTON_USE_TLS=${CANTON_USE_TLS:-true}
      - CANTON_PARTY=${CANTON_PARTY}
      - ETHEREUM_RPC_URL=${ETHEREUM_RPC_URL}
      - TREASURY_ADDRESS=${TREASURY_ADDRESS}
      - SMUSD_ADDRESS=${SMUSD_ADDRESS}
      - YIELD_SYNC_INTERVAL_MS=${YIELD_SYNC_INTERVAL_MS:-3600000}
      - MIN_YIELD_THRESHOLD=${MIN_YIELD_THRESHOLD:-1000000000}
      - NODE_ENV=production
    # Renamed from relayer_private_key to match code's readSecret('bridge_private_key')
    secrets:
      - canton_token
      - bridge_private_key
    restart: unless-stopped
    read_only: true
    tmpfs:
      - /tmp
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
    security_opt:
      - no-new-privileges:true
    networks:
      - bridge_internal
      - bridge_external
    healthcheck:
      test: ["CMD", "node", "-e", "const fs=require('fs');try{const s=fs.statSync('/tmp/heartbeat');process.exit(Date.now()-s.mtimeMs<300000?0:1)}catch(e){process.exit(1)}"]
      interval: 60s
      timeout: 10s
      retries: 3
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

  # ============================================================
  # VALIDATOR NODES
  # Each validator runs independently with their own KMS key
  # ============================================================
  validator1:
    build:
      context: .
      dockerfile: Dockerfile
    command: ["npm", "run", "validator:prod"]
    environment:
      - CANTON_HOST=${CANTON_HOST:-canton}
      - CANTON_PORT=${CANTON_PORT:-6865}
      - CANTON_USE_TLS=${CANTON_USE_TLS:-true}
      - VALIDATOR_PARTY=${VALIDATOR1_PARTY}
      - VALIDATOR_ETH_ADDRESS=${VALIDATOR1_ETH_ADDRESS}
      - KMS_KEY_ID=${VALIDATOR1_KMS_KEY_ID}
      - AWS_REGION=${AWS_REGION:-us-east-1}
      - BRIDGE_CONTRACT_ADDRESS=${BRIDGE_CONTRACT_ADDRESS}
      - MIN_COLLATERAL_RATIO_BPS=${MIN_COLLATERAL_RATIO_BPS:-11000}
      - POLL_INTERVAL_MS=${POLL_INTERVAL_MS:-3000}
      # Set NODE_ENV for HTTPS enforcement in validator-node-v2
      - NODE_ENV=production
    # Use secrets for AWS credentials
    secrets:
      - canton_token
      - validator1_aws_access_key
      - validator1_aws_secret_key
    restart: unless-stopped
    read_only: true
    tmpfs:
      - /tmp
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
    security_opt:
      - no-new-privileges:true
    networks:
      - bridge_internal
    # Healthcheck for validator (process-level since no HTTP endpoint)
    healthcheck:
      test: ["CMD", "node", "-e", "const fs=require('fs');try{const s=fs.statSync('/tmp/heartbeat');process.exit(Date.now()-s.mtimeMs<120000?0:1)}catch(e){process.exit(1)}"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

  validator2:
    build:
      context: .
      dockerfile: Dockerfile
    command: ["npm", "run", "validator:prod"]
    environment:
      - CANTON_HOST=${CANTON_HOST:-canton}
      - CANTON_PORT=${CANTON_PORT:-6865}
      - CANTON_USE_TLS=${CANTON_USE_TLS:-true}
      - VALIDATOR_PARTY=${VALIDATOR2_PARTY}
      - VALIDATOR_ETH_ADDRESS=${VALIDATOR2_ETH_ADDRESS}
      - KMS_KEY_ID=${VALIDATOR2_KMS_KEY_ID}
      - AWS_REGION=${AWS_REGION:-us-east-1}
      - BRIDGE_CONTRACT_ADDRESS=${BRIDGE_CONTRACT_ADDRESS}
      - MIN_COLLATERAL_RATIO_BPS=${MIN_COLLATERAL_RATIO_BPS:-11000}
      - POLL_INTERVAL_MS=${POLL_INTERVAL_MS:-3000}
      # Set NODE_ENV for HTTPS enforcement (was missing from validator2/3)
      - NODE_ENV=production
    secrets:
      - canton_token
      - validator2_aws_access_key
      - validator2_aws_secret_key
    restart: unless-stopped
    read_only: true
    tmpfs:
      - /tmp
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
    security_opt:
      - no-new-privileges:true
    networks:
      - bridge_internal
    # Healthcheck for validator (process-level)
    healthcheck:
      test: ["CMD", "node", "-e", "const fs=require('fs');try{const s=fs.statSync('/tmp/heartbeat');process.exit(Date.now()-s.mtimeMs<120000?0:1)}catch(e){process.exit(1)}"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

  validator3:
    build:
      context: .
      dockerfile: Dockerfile
    command: ["npm", "run", "validator:prod"]
    environment:
      - CANTON_HOST=${CANTON_HOST:-canton}
      - CANTON_PORT=${CANTON_PORT:-6865}
      - CANTON_USE_TLS=${CANTON_USE_TLS:-true}
      - VALIDATOR_PARTY=${VALIDATOR3_PARTY}
      - VALIDATOR_ETH_ADDRESS=${VALIDATOR3_ETH_ADDRESS}
      - KMS_KEY_ID=${VALIDATOR3_KMS_KEY_ID}
      - AWS_REGION=${AWS_REGION:-us-east-1}
      - BRIDGE_CONTRACT_ADDRESS=${BRIDGE_CONTRACT_ADDRESS}
      - MIN_COLLATERAL_RATIO_BPS=${MIN_COLLATERAL_RATIO_BPS:-11000}
      - POLL_INTERVAL_MS=${POLL_INTERVAL_MS:-3000}
      # Set NODE_ENV for HTTPS enforcement (was missing from validator2/3)
      - NODE_ENV=production
    secrets:
      - canton_token
      - validator3_aws_access_key
      - validator3_aws_secret_key
    restart: unless-stopped
    read_only: true
    tmpfs:
      - /tmp
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
    security_opt:
      - no-new-privileges:true
    networks:
      - bridge_internal
    # Healthcheck for validator (process-level)
    healthcheck:
      test: ["CMD", "node", "-e", "const fs=require('fs');try{const s=fs.statSync('/tmp/heartbeat');process.exit(Date.now()-s.mtimeMs<120000?0:1)}catch(e){process.exit(1)}"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
